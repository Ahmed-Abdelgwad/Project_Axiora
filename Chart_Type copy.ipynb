{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08303529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic LLM Config: \u001b[1mOllamaLLM\u001b[0m\n",
      "Params: {}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import tool\n",
    "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "import agentops\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import os\n",
    "import json\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define your local Ollama LLM\n",
    "llama3b = OllamaLLM(model=\"llama3.2:3b\", temperature=0)\n",
    "\n",
    "# Now use llama3b directly with Agent or Task setup\n",
    "# Example:\n",
    "print(\"Basic LLM Config:\", llama3b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b761b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_keywords = 10\n",
    "\n",
    "about_company = \"Axiora is a company that provides advanced artificial intelligence solutions focused on data analysis, intelligent insights extraction, and data visualization.\"\n",
    "company_context = StringKnowledgeSource(\n",
    "    content=about_company\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a034bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./ai-agent-output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3a299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────── Crew Execution Started ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">a4ea1952-efb0-4000-994d-20d5573b1771</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36ma4ea1952-efb0-4000-994d-20d5573b1771\u001b[0m                                                                       \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭───────────────────────────────────────────────── Crew Failure ──────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Crew Execution Failed</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">crew</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #800000; text-decoration-color: #800000\">a4ea1952-efb0-4000-994d-20d5573b1771</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────────────────────────\u001b[0m\u001b[31m Crew Failure \u001b[0m\u001b[31m─────────────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m  \u001b[1;31mCrew Execution Failed\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31mcrew\u001b[0m                                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[31ma4ea1952-efb0-4000-994d-20d5573b1771\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NoApiKeyException",
     "evalue": "Could not initialize AgentOps client - API Key is missing.\n\t    Find your API key at https://app.agentops.ai/settings/projects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoApiKeyException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 70\u001b[0m\n\u001b[0;32m     58\u001b[0m data_type_detection_crew \u001b[38;5;241m=\u001b[39m Crew(\n\u001b[0;32m     59\u001b[0m     agents\u001b[38;5;241m=\u001b[39m[data_type_detection_agent],\n\u001b[0;32m     60\u001b[0m     tasks\u001b[38;5;241m=\u001b[39m[data_type_detection_task],\n\u001b[0;32m     61\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     64\u001b[0m data_type_detection_crew \u001b[38;5;241m=\u001b[39m Crew(\n\u001b[0;32m     65\u001b[0m     agents\u001b[38;5;241m=\u001b[39m[data_type_detection_agent],\n\u001b[0;32m     66\u001b[0m     tasks\u001b[38;5;241m=\u001b[39m[data_type_detection_task],\n\u001b[0;32m     67\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     68\u001b[0m )\n\u001b[1;32m---> 70\u001b[0m crew_results \u001b[38;5;241m=\u001b[39m \u001b[43mdata_type_detection_crew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msales.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hasso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\crew.py:610\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    607\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    608\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m before_callback(inputs)\n\u001b[1;32m--> 610\u001b[0m \u001b[43mcrewai_event_bus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCrewKickoffStartedEvent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrew_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrew\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;66;03m# Starts the crew to work on its assigned tasks.\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_output_handler\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32mc:\\Users\\hasso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\utilities\\events\\crewai_event_bus.py:73\u001b[0m, in \u001b[0;36mCrewAIEventsBus.emit\u001b[1;34m(self, source, event)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, event_type):\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m---> 73\u001b[0m             \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal\u001b[38;5;241m.\u001b[39msend(source, event\u001b[38;5;241m=\u001b[39mevent)\n",
      "File \u001b[1;32mc:\\Users\\hasso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\utilities\\events\\third_party\\agentops_listener.py:33\u001b[0m, in \u001b[0;36mAgentOpsListener.setup_listeners.<locals>.on_crew_kickoff_started\u001b[1;34m(source, event)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;129m@crewai_event_bus\u001b[39m\u001b[38;5;241m.\u001b[39mon(CrewKickoffStartedEvent)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_crew_kickoff_started\u001b[39m(source, event: CrewKickoffStartedEvent):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m \u001b[43magentops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m source\u001b[38;5;241m.\u001b[39magents:\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession:\n",
      "File \u001b[1;32mc:\\Users\\hasso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\agentops\\__init__.py:90\u001b[0m, in \u001b[0;36minit\u001b[1;34m(api_key, endpoint, app_url, max_wait_time, max_queue_size, tags, default_tags, instrument_llm_calls, auto_start_session, auto_init, skip_auto_end_session, env_data_opt_out, log_level, fail_safe, exporter_endpoint, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m default_tags:\n\u001b[0;32m     88\u001b[0m     merged_tags \u001b[38;5;241m=\u001b[39m default_tags\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapp_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapp_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstrument_llm_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstrument_llm_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_start_session\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_start_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_auto_end_session\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_auto_end_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_data_opt_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_data_opt_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfail_safe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_safe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexporter_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexporter_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hasso\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\agentops\\client\\client.py:37\u001b[0m, in \u001b[0;36mClient.init\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigure(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mapi_key:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoApiKeyException\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# TODO we may need to initialize logging before importing OTEL to capture all\u001b[39;00m\n\u001b[0;32m     40\u001b[0m configure_logging(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "\u001b[1;31mNoApiKeyException\u001b[0m: Could not initialize AgentOps client - API Key is missing.\n\t    Find your API key at https://app.agentops.ai/settings/projects"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class DataUnderstandingOutput(BaseModel):\n",
    "    data_type: List[str] = Field(\n",
    "        ...,\n",
    "        title=\"Identified Data Type(s)\",\n",
    "        description=(\n",
    "            \"Clearly defines the nature of the data such as: \"\n",
    "            \"'structured', 'unstructured', 'time-series', 'image', 'text', etc.\"\n",
    "        )\n",
    "    )\n",
    "    structure: Dict[str, Any] = Field(\n",
    "        ...,\n",
    "        title=\"Data Structure Summary\",\n",
    "        description=(\n",
    "            \"Details how the data is organized. Includes format (e.g., CSV, JSON, Excel), \"\n",
    "            \"column names, data types, and a few representative sample values.\"\n",
    "        )\n",
    "    )\n",
    "    suggested_analysis: List[str] = Field(\n",
    "        ...,\n",
    "        title=\"Recommended Analytical or Visualization Techniques\",\n",
    "        description=(\n",
    "            \"List of suitable chart types or analytical approaches for this type of data. \"\n",
    "            \"For example: bar chart, line graph, scatter plot, word cloud, or summary statistics.\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "data_type_detection_agent = Agent(\n",
    "    role=\"Data Type Detection Agent\",\n",
    "    goal=\"\\n\".join([\n",
    "        \"Thoroughly analyze the provided input data {data} to accurately identify its type.\",\n",
    "        \"Determine whether the data is structured, unstructured, time-series, image, text, or any other relevant format.\",\n",
    "        \"Leverage this understanding to recommend the most suitable chart types for effective data visualization.\",\n",
    "        \"Return the identified data type(s) and corresponding chart suggestions in a clear, structured, and professional format.\"\n",
    "    ]),\n",
    "    backstory=\"This agent is designed to identify the type of input data and recommend appropriate visualization techniques to facilitate effective analysis and decision-making.\",\n",
    "    llm=\"ollama/llama3.2:3b\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "data_type_detection_task = Task(\n",
    "    description=\"\\n\".join([\n",
    "        \"Analyze the provided dataset: {data}.\",\n",
    "        \"Determine the type of the input data with high accuracy.\",\n",
    "        \"Identify whether the data is structured (e.g., tabular data, CSV), unstructured (e.g., free text, documents), time-series, image, or any other relevant format.\",\n",
    "        \"Focus solely on classifying the nature and format of the data based on its structure and content.\",\n",
    "        \"Return the classification in a clean and well-structured JSON format.\"\n",
    "    ]),\n",
    "    expected_output=\"A JSON object containing the detected data type(s) and a brief description of the data structure.\",\n",
    "    output_json=DataUnderstandingOutput,\n",
    "    output_file=os.path.join(output_dir, \"step_1_data_type_detection.json\"),\n",
    "    agent=data_type_detection_agent\n",
    ")\n",
    "\n",
    "# === Step 6: Setup the crew ===\n",
    "data_type_detection_crew = Crew(\n",
    "    agents=[data_type_detection_agent],\n",
    "    tasks=[data_type_detection_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "data_type_detection_crew = Crew(\n",
    "    agents=[data_type_detection_agent],\n",
    "    tasks=[data_type_detection_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "crew_results = data_type_detection_crew.kickoff(\n",
    "    inputs={\n",
    "        \"data\": \"sales.csv\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42ab4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the provided dataset: sales.csv.\n",
      "Determine the type of the input data with high accuracy.\n",
      "Identify whether the data is structured (e.g., tabular data, CSV), unstructured (e.g., free text, documents), time-series, image, or any other relevant format.\n",
      "Focus solely on classifying the nature and format of the data based on its structure and content.\n",
      "Return the classification in a clean and well-structured JSON format.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: Could not end session - no sessions detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\n",
      "  \"data_type\": [\"structured\"],\n",
      "  \"structure\": {\n",
      "    \"columns\": [\"Order ID\", \"Product ID\", \"Product Name\", \"Quantity\", \"Price\", \"Total\", \"Date\"],\n",
      "    \"data_types\": {\n",
      "      \"Order ID\": \"integer\",\n",
      "      \"Product ID\": \"integer\",\n",
      "      \"Product Name\": \"string\",\n",
      "      \"Quantity\": \"float\",\n",
      "      \"Price\": \"float\",\n",
      "      \"Total\": \"float\",\n",
      "      \"Date\": \"datetime\"\n",
      "    },\n",
      "    \"data_format\": \"csv\"\n",
      "  },\n",
      "  \"suggested_analysis\": [\n",
      "    \"Bar chart for Quantity, Product ID, or Order ID to visualize sales by product or order\",\n",
      "    \"Line chart for Total or Price over time to analyze trends in sales or pricing\",\n",
      "    \"Scatter plot for Total vs Price to identify outliers or correlations\",\n",
      "    \"Pie chart for Product Name to show the distribution of sales by product\"\n",
      "  ]\n",
      "}\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get Hugging Face API Key from Environment Variables\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "if not HUGGINGFACE_API_KEY:\n",
    "    raise ValueError(\"Hugging Face API key not found! Set HUGGINGFACE_API_KEY in your environment variables.\")\n",
    "\n",
    "# Define LLM using Hugging Face\n",
    "basic_llm = LLM(\n",
    "    model=\"huggingface/mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    api_key=HUGGINGFACE_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"./ai-agent-output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Company context\n",
    "about_company = \"Axiora is a company that provides advanced artificial intelligence solutions focused on data analysis, intelligent insights extraction, and data visualization.\"\n",
    "company_context = StringKnowledgeSource(content=about_company)\n",
    "\n",
    "# Output model\n",
    "class DataUnderstandingOutput(BaseModel):\n",
    "    data_type: List[str] = Field(\n",
    "        ..., title=\"Identified Data Type(s)\",\n",
    "        description=\"Clearly defines the nature of the data such as: 'structured', 'unstructured', 'time-series', 'image', 'text', etc.\"\n",
    "    )\n",
    "    structure: Dict[str, Any] = Field(\n",
    "        ..., title=\"Data Structure Summary\",\n",
    "        description=\"Details how the data is organized. Includes format (e.g., CSV, JSON, Excel), column names, data types, and a few sample values.\"\n",
    "    )\n",
    "    suggested_analysis: List[str] = Field(\n",
    "        ..., title=\"Recommended Analytical or Visualization Techniques\",\n",
    "        description=\"Suggested chart types or analytical approaches suitable for this data.\"\n",
    "    )\n",
    "\n",
    "# Define agent\n",
    "data_type_detection_agent = Agent(\n",
    "    role=\"Data Type Detection Agent\",\n",
    "    goal=\"\\n\".join([\n",
    "        \"Thoroughly analyze the provided input data {data} to accurately identify its type.\",\n",
    "        \"Determine whether the data is structured, unstructured, time-series, image, text, or any other relevant format.\",\n",
    "        \"Leverage this understanding to recommend the most suitable chart types for effective data visualization.\",\n",
    "        \"Return the identified data type(s) and corresponding chart suggestions in a clear, structured, and professional format.\"\n",
    "    ]),\n",
    "    backstory=\"This agent is designed to identify the type of input data and recommend appropriate visualization techniques to facilitate effective analysis and decision-making.\",\n",
    "    llm=basic_llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define task\n",
    "data_type_detection_task = Task(\n",
    "    description=\"\\n\".join([\n",
    "        \"Analyze the provided dataset: {data}.\",\n",
    "        \"Determine the type of the input data with high accuracy.\",\n",
    "        \"Identify whether the data is structured (e.g., tabular data, CSV), unstructured (e.g., free text, documents), time-series, image, or any other relevant format.\",\n",
    "        \"Focus solely on classifying the nature and format of the data based on its structure and content.\",\n",
    "        \"Return the classification in a clean and well-structured JSON format.\"\n",
    "    ]),\n",
    "    expected_output=\"A JSON object containing the detected data type(s) and a brief description of the data structure.\",\n",
    "    output_json=DataUnderstandingOutput,\n",
    "    output_file=os.path.join(output_dir, \"step_1_data_type_detection.json\"),\n",
    "    agent=data_type_detection_agent\n",
    ")\n",
    "\n",
    "# Setup the crew\n",
    "data_type_detection_crew = Crew(\n",
    "    agents=[data_type_detection_agent],\n",
    "    tasks=[data_type_detection_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "crew_results = data_type_detection_crew.kickoff(\n",
    "    inputs={\n",
    "        \"data\": \"sales.csv\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9859678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the provided dataset preview and metadata.\n",
      "Accurately determine the type of data (e.g., structured, unstructured, time-series, etc.).\n",
      "Make sure to mention ALL column names, their data types, and a few sample values.\n",
      "Return your results in a well-structured JSON format that includes data type, structure, and recommended analysis.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\n",
      "  \"data_type\": [\"structured\"],\n",
      "  \"structure\": {\n",
      "    \"column_names\": [\n",
      "      \"rows\",\n",
      "      \"columns_count\",\n",
      "      \"note\",\n",
      "      \"Column1\",\n",
      "      \"Column2\",\n",
      "      ...,\n",
      "      \"Column20\"\n",
      "    ],\n",
      "    \"data_types\": [\n",
      "      \"int\",\n",
      "      \"int\",\n",
      "      \"str\",\n",
      "      \"str\",\n",
      "      \"str\",\n",
      "      ...,\n",
      "      \"str\"\n",
      "    ],\n",
      "    \"sample_values\": {\n",
      "      \"Column1\": [\"value1\", \"value2\", ..., \"valuen\"],\n",
      "      \"Column2\": [\"value1\", \"value2\", ..., \"valuen\"],\n",
      "      ...,\n",
      "      \"Column20\": [\"value1\", \"value2\", ..., \"valuen\"]\n",
      "    }\n",
      "  },\n",
      "  \"suggested_analysis\": [\n",
      "    \"Exploratory Data Analysis (EDA) to understand the distribution and relationships between variables.\",\n",
      "    \"Correlation analysis to identify relationships between columns.\",\n",
      "    \"Descriptive statistics for each column.\",\n",
      "    \"Visualizations such as bar charts, scatter plots, heatmaps, etc., to better understand the data.\",\n",
      "    \"Inferential statistics if applicable (e.g., hypothesis testing, regression analysis).\"\n",
      "  ]\n",
      "}\n",
      "```\u001b[00m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: Could not end session - no sessions detected\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables (if needed)\n",
    "load_dotenv()\n",
    "\n",
    "# Set up LLM using Ollama locally\n",
    "basic_llm = LLM(\n",
    "    model=\"ollama/mistral:instruct\",  # يمكنك تغيير النموذج إلى llama3 مثلاً\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"./ai-agent-output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Company context (optional)\n",
    "about_company = \"Axiora is a company that provides advanced artificial intelligence solutions focused on data analysis, intelligent insights extraction, and data visualization.\"\n",
    "company_context = StringKnowledgeSource(content=about_company)\n",
    "\n",
    "# Output schema\n",
    "class DataUnderstandingOutput(BaseModel):\n",
    "    data_type: List[str] = Field(\n",
    "        ..., title=\"Identified Data Type(s)\",\n",
    "        description=\"Clearly defines the nature of the data such as: 'structured', 'unstructured', 'time-series', 'image', 'text', etc.\"\n",
    "    )\n",
    "    structure: Dict[str, Any] = Field(\n",
    "        ..., title=\"Data Structure Summary\",\n",
    "        description=\"Details how the data is organized. Includes format (e.g., CSV, JSON, Excel), column names, data types, and a few sample values.\"\n",
    "    )\n",
    "    suggested_analysis: List[str] = Field(\n",
    "        ..., title=\"Recommended Analytical or Visualization Techniques\",\n",
    "        description=\"Suggested chart types or analytical approaches suitable for this data.\"\n",
    "    )\n",
    "\n",
    "# Load dataset and prepare structured input\n",
    "def load_dataset(file_path: str) -> str:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        sample_data = df.head(5).to_dict(orient=\"records\")\n",
    "        structure_info = {\n",
    "            \"format\": \"CSV\",\n",
    "            \"columns\": list(df.columns),\n",
    "            \"column_types\": df.dtypes.astype(str).to_dict(),\n",
    "            \"sample_values\": sample_data,\n",
    "            \"rows\": df.shape[0],\n",
    "            \"columns_count\": df.shape[1],\n",
    "            \"note\": f\"The dataset contains {df.shape[1]} columns. Please include ALL columns in your analysis.\"\n",
    "        }\n",
    "        return json.dumps(structure_info, indent=2)\n",
    "    except Exception as e:\n",
    "        return f\"Error loading dataset: {e}\"\n",
    "\n",
    "# Define the agent\n",
    "data_type_detection_agent = Agent(\n",
    "    role=\"Data Type Detection Agent\",\n",
    "    goal=\"\\n\".join([\n",
    "        \"Analyze the provided input data {data} to identify its type and structure.\",\n",
    "        \"Ensure that ALL columns in the dataset are included in your output — do not omit any.\",\n",
    "        \"Use the structure preview to infer appropriate chart types or visualizations.\",\n",
    "        \"Return a clean, structured JSON object with your findings.\"\n",
    "    ]),\n",
    "    backstory=\"This agent is specialized in identifying the structure of datasets and recommending suitable visualizations for exploratory data analysis.\",\n",
    "    llm=basic_llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define the task\n",
    "data_type_detection_task = Task(\n",
    "    description=\"\\n\".join([\n",
    "        \"Analyze the provided dataset preview and metadata.\",\n",
    "        \"Accurately determine the type of data (e.g., structured, unstructured, time-series, etc.).\",\n",
    "        \"Make sure to mention ALL column names, their data types, and a few sample values.\",\n",
    "        \"Return your results in a well-structured JSON format that includes data type, structure, and recommended analysis.\"\n",
    "    ]),\n",
    "    expected_output=\"A JSON object containing the detected data type(s), full column structure, and suggested analysis.\",\n",
    "    output_json=DataUnderstandingOutput,\n",
    "    output_file=os.path.join(output_dir, \"step_1_data_type_detection.json\"),\n",
    "    agent=data_type_detection_agent\n",
    ")\n",
    "\n",
    "# Set up the crew\n",
    "data_type_detection_crew = Crew(\n",
    "    agents=[data_type_detection_agent],\n",
    "    tasks=[data_type_detection_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Load data and run the crew\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"sales.csv\"  # ← تأكد من مسار الملف\n",
    "    dataset_content = load_dataset(dataset_path)\n",
    "\n",
    "    crew_results = data_type_detection_crew.kickoff(\n",
    "        inputs={\n",
    "            \"data\": dataset_content\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c12b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "You are given a sample of a dataset including its first 5 rows and column schema.\n",
      "\n",
      "Your task is to:\n",
      "1. Accurately determine the overall type of the dataset.\n",
      "   - Choose one or more of the following: \"structured\", \"unstructured\", \"time-series\", \"text\", \"image\", etc.\n",
      "2. List all column names along with their corresponding data types (such as int64, float64, object, datetime64, etc.).\n",
      "\n",
      "Do not perform any data cleaning, visualization suggestions, or further analysis.\n",
      "\n",
      "Respond only in structured JSON format that conforms exactly to the following schema:\n",
      "\n",
      "{\n",
      "  \"data_type\": \"<overall_data_type>\",\n",
      "  \"columns\": [\n",
      "    { \"column_name\": \"<name1>\", \"data_type\": \"<type1>\" },\n",
      "    ...\n",
      "  ]\n",
      "}\n",
      "\n",
      "### Dataset Preview:\n",
      "[{\"orderid\":1,\"Customer Name\":\"Muhammed MacIntyre\",\"shipmode\":\"First Class\",\"sales\":825.174,\"quantity\":9,\"discount\":0.3,\"profit\":-117.882,\"segment\":\"Corporate\",\"region\":\"Central\",\"state\":\"Illinois\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":4,\"orderdate_weekday\":\"Sonntag\",\"orderdate_month\":9,\"orderdate_year\":2016,\"shipdate_day\":6,\"shipdate_month\":9,\"shipdate_year\":2016,\"preparationtime\":2},{\"orderid\":2,\"Customer Name\":\"Ruben Dartt\",\"shipmode\":\"Standard Class\",\"sales\":411.332,\"quantity\":4,\"discount\":0.15,\"profit\":-4.8392,\"segment\":\"Consumer\",\"region\":\"West\",\"state\":\"California\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":5,\"orderdate_weekday\":\"Freitag\",\"orderdate_month\":9,\"orderdate_year\":2014,\"shipdate_day\":9,\"shipdate_month\":9,\"shipdate_year\":2014,\"preparationtime\":4},{\"orderid\":3,\"Customer Name\":\"Liz Pelletier\",\"shipmode\":\"Same Day\",\"sales\":411.332,\"quantity\":4,\"discount\":0.15,\"profit\":-4.8392,\"segment\":\"Home Office\",\"region\":\"West\",\"state\":\"California\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":28,\"orderdate_weekday\":\"Donnerstag\",\"orderdate_month\":11,\"orderdate_year\":2013,\"shipdate_day\":28,\"shipdate_month\":11,\"shipdate_year\":2013,\"preparationtime\":0},{\"orderid\":4,\"Customer Name\":\"Liz Pelletier\",\"shipmode\":\"First Class\",\"sales\":241.96,\"quantity\":2,\"discount\":0.0,\"profit\":33.8744,\"segment\":\"Consumer\",\"region\":\"South\",\"state\":\"Louisiana\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":30,\"orderdate_weekday\":\"Montag\",\"orderdate_month\":5,\"orderdate_year\":2016,\"shipdate_day\":31,\"shipdate_month\":5,\"shipdate_year\":2016,\"preparationtime\":1},{\"orderid\":5,\"Customer Name\":\"Liz Pelletier\",\"shipmode\":\"Standard Class\",\"sales\":341.96,\"quantity\":2,\"discount\":0.0,\"profit\":78.6508,\"segment\":\"Home Office\",\"region\":\"East\",\"state\":\"Rhode Island\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":31,\"orderdate_weekday\":\"Dienstag\",\"orderdate_month\":12,\"orderdate_year\":2013,\"shipdate_day\":7,\"shipdate_month\":1,\"shipdate_year\":2014,\"preparationtime\":7}]\n",
      "\n",
      "### Column Schema:\n",
      "- orderid: int64\n",
      "- Customer Name: object\n",
      "- shipmode: object\n",
      "- sales: float64\n",
      "- quantity: int64\n",
      "- discount: float64\n",
      "- profit: float64\n",
      "- segment: object\n",
      "- region: object\n",
      "- state: object\n",
      "- subcategory: object\n",
      "- category: object\n",
      "- orderdate_day: int64\n",
      "- orderdate_weekday: object\n",
      "- orderdate_month: int64\n",
      "- orderdate_year: int64\n",
      "- shipdate_day: int64\n",
      "- shipdate_month: int64\n",
      "- shipdate_year: int64\n",
      "- preparationtime: int64\n",
      "\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: Could not end session - no sessions detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\n",
      "  \"data_type\": \"structured\",\n",
      "  \"columns\": [\n",
      "    { \"column_name\": \"orderid\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"Customer Name\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"shipmode\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"sales\", \"data_type\": \"float64\" },\n",
      "    { \"column_name\": \"quantity\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"discount\", \"data_type\": \"float64\" },\n",
      "    { \"column_name\": \"profit\", \"data_type\": \"float64\" },\n",
      "    { \"column_name\": \"segment\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"region\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"state\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"subcategory\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"category\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"orderdate_day\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"orderdate_weekday\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"orderdate_month\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"orderdate_year\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"shipdate_day\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"shipdate_month\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"shipdate_year\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"preparationtime\", \"data_type\": \"int64\" }\n",
      "  ]\n",
      "}\n",
      "```\u001b[00m\n",
      "\n",
      "\n",
      "{'data_type': 'structured', 'columns': [{'column_name': 'orderid', 'data_type': 'int64'}, {'column_name': 'Customer Name', 'data_type': 'object'}, {'column_name': 'shipmode', 'data_type': 'object'}, {'column_name': 'sales', 'data_type': 'float64'}, {'column_name': 'quantity', 'data_type': 'int64'}, {'column_name': 'discount', 'data_type': 'float64'}, {'column_name': 'profit', 'data_type': 'float64'}, {'column_name': 'segment', 'data_type': 'object'}, {'column_name': 'region', 'data_type': 'object'}, {'column_name': 'state', 'data_type': 'object'}, {'column_name': 'subcategory', 'data_type': 'object'}, {'column_name': 'category', 'data_type': 'object'}, {'column_name': 'orderdate_day', 'data_type': 'int64'}, {'column_name': 'orderdate_weekday', 'data_type': 'object'}, {'column_name': 'orderdate_month', 'data_type': 'int64'}, {'column_name': 'orderdate_year', 'data_type': 'int64'}, {'column_name': 'shipdate_day', 'data_type': 'int64'}, {'column_name': 'shipdate_month', 'data_type': 'int64'}, {'column_name': 'shipdate_year', 'data_type': 'int64'}, {'column_name': 'preparationtime', 'data_type': 'int64'}]}\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (if needed)\n",
    "load_dotenv()\n",
    "\n",
    "# Setup LLM (using Ollama locally)\n",
    "llm = LLM(\n",
    "    model=\"ollama/mistral:instruct\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"./ai-agent-output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --------- 1. Define Output Schema ---------\n",
    "class ColumnInfo(BaseModel):\n",
    "    column_name: str = Field(..., description=\"Name of the column\")\n",
    "    data_type: str = Field(..., description=\"Data type of the column (e.g., int, float, string, datetime)\")\n",
    "\n",
    "class DataUnderstandingOutput(BaseModel):\n",
    "    data_type: str = Field(..., description=\"Overall type of the dataset: structured, unstructured, time-series, etc.\")\n",
    "    columns: List[ColumnInfo] = Field(..., description=\"List of column names with their data types\")\n",
    "\n",
    "# --------- 2. Load and Preview the Dataset ---------\n",
    "# Load your dataset (replace this with the path to your file)\n",
    "df = pd.read_csv(\"sales.csv\")\n",
    "\n",
    "# Get the first few rows as preview\n",
    "data_preview = df.head(5).to_json(orient=\"records\", lines=False)\n",
    "\n",
    "# Get column schema\n",
    "column_schema = df.dtypes.apply(lambda x: str(x)).to_dict()\n",
    "\n",
    "# Convert to formatted string for prompt\n",
    "formatted_column_schema = \"\\n\".join([f\"- {col}: {dtype}\" for col, dtype in column_schema.items()])\n",
    "\n",
    "# --------- 3. Build Prompt Template ---------\n",
    "prompt_template = f\"\"\"\n",
    "You are given a sample of a dataset including its first 5 rows and column schema.\n",
    "\n",
    "Your task is to:\n",
    "1. Accurately determine the overall type of the dataset.\n",
    "   - Choose one or more of the following: \"structured\", \"unstructured\", \"time-series\", \"text\", \"image\", etc.\n",
    "2. List all column names along with their corresponding data types (such as int64, float64, object, datetime64, etc.).\n",
    "\n",
    "Do not perform any data cleaning, visualization suggestions, or further analysis.\n",
    "\n",
    "Respond only in structured JSON format that conforms exactly to the following schema:\n",
    "\n",
    "{{\n",
    "  \"data_type\": \"<overall_data_type>\",\n",
    "  \"columns\": [\n",
    "    {{ \"column_name\": \"<name1>\", \"data_type\": \"<type1>\" }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "### Dataset Preview:\n",
    "{data_preview}\n",
    "\n",
    "### Column Schema:\n",
    "{formatted_column_schema}\n",
    "\"\"\"\n",
    "\n",
    "# --------- 4. Define Agent ---------\n",
    "agent = Agent(\n",
    "    role=\"Data Type Detection Agent\",\n",
    "    goal=\"Identify the overall type of a dataset and list its columns and their data types.\",\n",
    "    backstory=\"This agent specializes in understanding data formats for structured and unstructured datasets.\",\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# --------- 5. Define Task ---------\n",
    "task = Task(\n",
    "    description=prompt_template,\n",
    "    expected_output=\"JSON object with 'data_type' and 'columns' fields describing the dataset structure.\",\n",
    "    output_json=DataUnderstandingOutput,\n",
    "    output_file=os.path.join(output_dir, \"data_structure_analysis.json\"),\n",
    "    agent=agent,\n",
    ")\n",
    "\n",
    "# --------- 6. Run the Crew ---------\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
