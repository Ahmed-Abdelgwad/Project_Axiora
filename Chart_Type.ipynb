{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08303529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai.tools import tool\n",
    "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "import agentops\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from typing import List, Optional\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "# Get Hugging Face API Key from Environment Variables\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "# Ensure API Key is Provided\n",
    "if not HUGGINGFACE_API_KEY:\n",
    "    raise ValueError(\"Hugging Face API key not found! Set HUGGINGFACE_API_KEY in your environment variables.\")\n",
    "\n",
    "# Define LLM using Hugging Face\n",
    "basic_llm = LLM(\n",
    "    model=\"huggingface/mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    api_key=HUGGINGFACE_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b761b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_keywords = 10\n",
    "\n",
    "about_company = \"Axiora is a company that provides advanced artificial intelligence solutions focused on data analysis, intelligent insights extraction, and data visualization.\"\n",
    "company_context = StringKnowledgeSource(\n",
    "    content=about_company\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a034bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./ai-agent-output\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3a299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the provided dataset: sales.csv.\n",
      "Determine the type of the input data with high accuracy.\n",
      "Identify whether the data is structured (e.g., tabular data, CSV), unstructured (e.g., free text, documents), time-series, image, or any other relevant format.\n",
      "Focus solely on classifying the nature and format of the data based on its structure and content.\n",
      "Return the classification in a clean and well-structured JSON format.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: Could not end session - no sessions detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\n",
      "  \"data_type\": [\"structured\", \"tabular\"],\n",
      "  \"structure\": {\n",
      "    \"columns\": [\"Order ID\", \"Product\", \"Sales\", \"Date\"],\n",
      "    \"data_types\": {\n",
      "      \"Order ID\": \"integer\",\n",
      "      \"Product\": \"string\",\n",
      "      \"Sales\": \"float\",\n",
      "      \"Date\": \"datetime\"\n",
      "    },\n",
      "    \"row_count\": 1000,\n",
      "    \"column_count\": 4\n",
      "  },\n",
      "  \"suggested_analysis\": [\n",
      "    \"Line chart for Sales over time\",\n",
      "    \"Bar chart for Sales by Product\",\n",
      "    \"Scatter plot for Sales vs. Date\",\n",
      "    \"Pie chart for Sales distribution by Product\"\n",
      "  ]\n",
      "}\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class DataUnderstandingOutput(BaseModel):\n",
    "    data_type: List[str] = Field(\n",
    "        ...,\n",
    "        title=\"Identified Data Type(s)\",\n",
    "        description=(\n",
    "            \"Clearly defines the nature of the data such as: \"\n",
    "            \"'structured', 'unstructured', 'time-series', 'image', 'text', etc.\"\n",
    "        )\n",
    "    )\n",
    "    structure: Dict[str, Any] = Field(\n",
    "        ...,\n",
    "        title=\"Data Structure Summary\",\n",
    "        description=(\n",
    "            \"Details how the data is organized. Includes format (e.g., CSV, JSON, Excel), \"\n",
    "            \"column names, data types, and a few representative sample values.\"\n",
    "        )\n",
    "    )\n",
    "    suggested_analysis: List[str] = Field(\n",
    "        ...,\n",
    "        title=\"Recommended Analytical or Visualization Techniques\",\n",
    "        description=(\n",
    "            \"List of suitable chart types or analytical approaches for this type of data. \"\n",
    "            \"For example: bar chart, line graph, scatter plot, word cloud, or summary statistics.\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "data_type_detection_agent = Agent(\n",
    "    role=\"Data Type Detection Agent\",\n",
    "    goal=\"\\n\".join([\n",
    "        \"Thoroughly analyze the provided input data {data} to accurately identify its type.\",\n",
    "        \"Determine whether the data is structured, unstructured, time-series, image, text, or any other relevant format.\",\n",
    "        \"Leverage this understanding to recommend the most suitable chart types for effective data visualization.\",\n",
    "        \"Return the identified data type(s) and corresponding chart suggestions in a clear, structured, and professional format.\"\n",
    "    ]),\n",
    "    backstory=\"This agent is designed to identify the type of input data and recommend appropriate visualization techniques to facilitate effective analysis and decision-making.\",\n",
    "    llm=basic_llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "data_type_detection_task = Task(\n",
    "    description=\"\\n\".join([\n",
    "        \"Analyze the provided dataset: {data}.\",\n",
    "        \"Determine the type of the input data with high accuracy.\",\n",
    "        \"Identify whether the data is structured (e.g., tabular data, CSV), unstructured (e.g., free text, documents), time-series, image, or any other relevant format.\",\n",
    "        \"Focus solely on classifying the nature and format of the data based on its structure and content.\",\n",
    "        \"Return the classification in a clean and well-structured JSON format.\"\n",
    "    ]),\n",
    "    expected_output=\"A JSON object containing the detected data type(s) and a brief description of the data structure.\",\n",
    "    output_json=DataUnderstandingOutput,\n",
    "    output_file=os.path.join(output_dir, \"step_1_data_type_detection.json\"),\n",
    "    agent=data_type_detection_agent\n",
    ")\n",
    "\n",
    "# === Step 6: Setup the crew ===\n",
    "data_type_detection_crew = Crew(\n",
    "    agents=[data_type_detection_agent],\n",
    "    tasks=[data_type_detection_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "data_type_detection_crew = Crew(\n",
    "    agents=[data_type_detection_agent],\n",
    "    tasks=[data_type_detection_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "crew_results = data_type_detection_crew.kickoff(\n",
    "    inputs={\n",
    "        \"data\": \"sales.csv\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a42ab4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the provided dataset: sales.csv.\n",
      "Determine the type of the input data with high accuracy.\n",
      "Identify whether the data is structured (e.g., tabular data, CSV), unstructured (e.g., free text, documents), time-series, image, or any other relevant format.\n",
      "Focus solely on classifying the nature and format of the data based on its structure and content.\n",
      "Return the classification in a clean and well-structured JSON format.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: Could not end session - no sessions detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\n",
      "  \"data_type\": [\"structured\", \"tabular\"],\n",
      "  \"structure\": {\n",
      "    \"columns\": [\"Order ID\", \"Product\", \"Sales\", \"Date\"],\n",
      "    \"data_types\": {\n",
      "      \"Order ID\": \"integer\",\n",
      "      \"Product\": \"string\",\n",
      "      \"Sales\": \"float\",\n",
      "      \"Date\": \"datetime\"\n",
      "    },\n",
      "    \"row_count\": 1000,\n",
      "    \"column_count\": 4\n",
      "  },\n",
      "  \"suggested_analysis\": [\n",
      "    \"Line chart for Sales over time\",\n",
      "    \"Bar chart for Sales by Product\",\n",
      "    \"Scatter plot for Sales vs. Date\",\n",
      "    \"Pie chart for Sales distribution by Product\"\n",
      "  ]\n",
      "}\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get Hugging Face API Key from Environment Variables\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "if not HUGGINGFACE_API_KEY:\n",
    "    raise ValueError(\"Hugging Face API key not found! Set HUGGINGFACE_API_KEY in your environment variables.\")\n",
    "\n",
    "# Define LLM using Hugging Face\n",
    "basic_llm = LLM(\n",
    "    model=\"huggingface/mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    api_key=HUGGINGFACE_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"./ai-agent-output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Company context\n",
    "about_company = \"Axiora is a company that provides advanced artificial intelligence solutions focused on data analysis, intelligent insights extraction, and data visualization.\"\n",
    "company_context = StringKnowledgeSource(content=about_company)\n",
    "\n",
    "# Output model\n",
    "class DataUnderstandingOutput(BaseModel):\n",
    "    data_type: List[str] = Field(\n",
    "        ..., title=\"Identified Data Type(s)\",\n",
    "        description=\"Clearly defines the nature of the data such as: 'structured', 'unstructured', 'time-series', 'image', 'text', etc.\"\n",
    "    )\n",
    "    structure: Dict[str, Any] = Field(\n",
    "        ..., title=\"Data Structure Summary\",\n",
    "        description=\"Details how the data is organized. Includes format (e.g., CSV, JSON, Excel), column names, data types, and a few sample values.\"\n",
    "    )\n",
    "    suggested_analysis: List[str] = Field(\n",
    "        ..., title=\"Recommended Analytical or Visualization Techniques\",\n",
    "        description=\"Suggested chart types or analytical approaches suitable for this data.\"\n",
    "    )\n",
    "\n",
    "# Define agent\n",
    "data_type_detection_agent = Agent(\n",
    "    role=\"Data Type Detection Agent\",\n",
    "    goal=\"\\n\".join([\n",
    "        \"Thoroughly analyze the provided input data {data} to accurately identify its type.\",\n",
    "        \"Determine whether the data is structured, unstructured, time-series, image, text, or any other relevant format.\",\n",
    "        \"Leverage this understanding to recommend the most suitable chart types for effective data visualization.\",\n",
    "        \"Return the identified data type(s) and corresponding chart suggestions in a clear, structured, and professional format.\"\n",
    "    ]),\n",
    "    backstory=\"This agent is designed to identify the type of input data and recommend appropriate visualization techniques to facilitate effective analysis and decision-making.\",\n",
    "    llm=basic_llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define task\n",
    "data_type_detection_task = Task(\n",
    "    description=\"\\n\".join([\n",
    "        \"Analyze the provided dataset: {data}.\",\n",
    "        \"Determine the type of the input data with high accuracy.\",\n",
    "        \"Identify whether the data is structured (e.g., tabular data, CSV), unstructured (e.g., free text, documents), time-series, image, or any other relevant format.\",\n",
    "        \"Focus solely on classifying the nature and format of the data based on its structure and content.\",\n",
    "        \"Return the classification in a clean and well-structured JSON format.\"\n",
    "    ]),\n",
    "    expected_output=\"A JSON object containing the detected data type(s) and a brief description of the data structure.\",\n",
    "    output_json=DataUnderstandingOutput,\n",
    "    output_file=os.path.join(output_dir, \"step_1_data_type_detection.json\"),\n",
    "    agent=data_type_detection_agent\n",
    ")\n",
    "\n",
    "# Setup the crew\n",
    "data_type_detection_crew = Crew(\n",
    "    agents=[data_type_detection_agent],\n",
    "    tasks=[data_type_detection_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "crew_results = data_type_detection_crew.kickoff(\n",
    "    inputs={\n",
    "        \"data\": \"sales.csv\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6009dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "You are given a sample of a dataset including its first 5 rows and column schema.\n",
      "\n",
      "Your task is to:\n",
      "1. Accurately determine the overall type of the dataset.\n",
      "   - Choose one or more of the following: \"structured\", \"unstructured\", \"time-series\", \"text\", \"image\", etc.\n",
      "2. List all column names along with their corresponding data types (such as int64, float64, object, datetime64, etc.).\n",
      "\n",
      "Do not perform any data cleaning, visualization suggestions, or further analysis.\n",
      "\n",
      "Respond only in structured JSON format that conforms exactly to the following schema:\n",
      "\n",
      "{\n",
      "  \"data_type\": \"<overall_data_type>\",\n",
      "  \"columns\": [\n",
      "    { \"column_name\": \"<name1>\", \"data_type\": \"<type1>\" },\n",
      "    ...\n",
      "  ]\n",
      "}\n",
      "\n",
      "### Dataset Preview:\n",
      "[{\"orderid\":1,\"Customer Name\":\"Muhammed MacIntyre\",\"shipmode\":\"First Class\",\"sales\":825.174,\"quantity\":9,\"discount\":0.3,\"profit\":-117.882,\"segment\":\"Corporate\",\"region\":\"Central\",\"state\":\"Illinois\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":4,\"orderdate_weekday\":\"Sonntag\",\"orderdate_month\":9,\"orderdate_year\":2016,\"shipdate_day\":6,\"shipdate_month\":9,\"shipdate_year\":2016,\"preparationtime\":2},{\"orderid\":2,\"Customer Name\":\"Ruben Dartt\",\"shipmode\":\"Standard Class\",\"sales\":411.332,\"quantity\":4,\"discount\":0.15,\"profit\":-4.8392,\"segment\":\"Consumer\",\"region\":\"West\",\"state\":\"California\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":5,\"orderdate_weekday\":\"Freitag\",\"orderdate_month\":9,\"orderdate_year\":2014,\"shipdate_day\":9,\"shipdate_month\":9,\"shipdate_year\":2014,\"preparationtime\":4},{\"orderid\":3,\"Customer Name\":\"Liz Pelletier\",\"shipmode\":\"Same Day\",\"sales\":411.332,\"quantity\":4,\"discount\":0.15,\"profit\":-4.8392,\"segment\":\"Home Office\",\"region\":\"West\",\"state\":\"California\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":28,\"orderdate_weekday\":\"Donnerstag\",\"orderdate_month\":11,\"orderdate_year\":2013,\"shipdate_day\":28,\"shipdate_month\":11,\"shipdate_year\":2013,\"preparationtime\":0},{\"orderid\":4,\"Customer Name\":\"Liz Pelletier\",\"shipmode\":\"First Class\",\"sales\":241.96,\"quantity\":2,\"discount\":0.0,\"profit\":33.8744,\"segment\":\"Consumer\",\"region\":\"South\",\"state\":\"Louisiana\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":30,\"orderdate_weekday\":\"Montag\",\"orderdate_month\":5,\"orderdate_year\":2016,\"shipdate_day\":31,\"shipdate_month\":5,\"shipdate_year\":2016,\"preparationtime\":1},{\"orderid\":5,\"Customer Name\":\"Liz Pelletier\",\"shipmode\":\"Standard Class\",\"sales\":341.96,\"quantity\":2,\"discount\":0.0,\"profit\":78.6508,\"segment\":\"Home Office\",\"region\":\"East\",\"state\":\"Rhode Island\",\"subcategory\":\"Bookcases                                         \",\"category\":\"Furniture\",\"orderdate_day\":31,\"orderdate_weekday\":\"Dienstag\",\"orderdate_month\":12,\"orderdate_year\":2013,\"shipdate_day\":7,\"shipdate_month\":1,\"shipdate_year\":2014,\"preparationtime\":7}]\n",
      "\n",
      "### Column Schema:\n",
      "- orderid: int64\n",
      "- Customer Name: object\n",
      "- shipmode: object\n",
      "- sales: float64\n",
      "- quantity: int64\n",
      "- discount: float64\n",
      "- profit: float64\n",
      "- segment: object\n",
      "- region: object\n",
      "- state: object\n",
      "- subcategory: object\n",
      "- category: object\n",
      "- orderdate_day: int64\n",
      "- orderdate_weekday: object\n",
      "- orderdate_month: int64\n",
      "- orderdate_year: int64\n",
      "- shipdate_day: int64\n",
      "- shipdate_month: int64\n",
      "- shipdate_year: int64\n",
      "- preparationtime: int64\n",
      "\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: Could not end session - no sessions detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Type Detection Agent\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\n",
      "  \"data_type\": \"structured\",\n",
      "  \"columns\": [\n",
      "    { \"column_name\": \"orderid\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"Customer Name\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"shipmode\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"sales\", \"data_type\": \"float64\" },\n",
      "    { \"column_name\": \"quantity\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"discount\", \"data_type\": \"float64\" },\n",
      "    { \"column_name\": \"profit\", \"data_type\": \"float64\" },\n",
      "    { \"column_name\": \"segment\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"region\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"state\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"subcategory\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"category\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"orderdate_day\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"orderdate_weekday\", \"data_type\": \"object\" },\n",
      "    { \"column_name\": \"orderdate_month\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"orderdate_year\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"shipdate_day\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"shipdate_month\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"shipdate_year\", \"data_type\": \"int64\" },\n",
      "    { \"column_name\": \"preparationtime\", \"data_type\": \"int64\" }\n",
      "  ]\n",
      "}\n",
      "```\u001b[00m\n",
      "\n",
      "\n",
      "{'data_type': 'structured', 'columns': [{'column_name': 'orderid', 'data_type': 'int64'}, {'column_name': 'Customer Name', 'data_type': 'object'}, {'column_name': 'shipmode', 'data_type': 'object'}, {'column_name': 'sales', 'data_type': 'float64'}, {'column_name': 'quantity', 'data_type': 'int64'}, {'column_name': 'discount', 'data_type': 'float64'}, {'column_name': 'profit', 'data_type': 'float64'}, {'column_name': 'segment', 'data_type': 'object'}, {'column_name': 'region', 'data_type': 'object'}, {'column_name': 'state', 'data_type': 'object'}, {'column_name': 'subcategory', 'data_type': 'object'}, {'column_name': 'category', 'data_type': 'object'}, {'column_name': 'orderdate_day', 'data_type': 'int64'}, {'column_name': 'orderdate_weekday', 'data_type': 'object'}, {'column_name': 'orderdate_month', 'data_type': 'int64'}, {'column_name': 'orderdate_year', 'data_type': 'int64'}, {'column_name': 'shipdate_day', 'data_type': 'int64'}, {'column_name': 'shipdate_month', 'data_type': 'int64'}, {'column_name': 'shipdate_year', 'data_type': 'int64'}, {'column_name': 'preparationtime', 'data_type': 'int64'}]}\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (if needed)\n",
    "load_dotenv()\n",
    "\n",
    "# Setup LLM (using Ollama locally)\n",
    "llm = LLM(\n",
    "    model=\"ollama/mistral:instruct\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"./ai-agent-output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --------- 1. Define Output Schema ---------\n",
    "class ColumnInfo(BaseModel):\n",
    "    column_name: str = Field(..., description=\"Name of the column\")\n",
    "    data_type: str = Field(..., description=\"Data type of the column (e.g., int, float, string, datetime)\")\n",
    "\n",
    "class DataUnderstandingOutput(BaseModel):\n",
    "    data_type: str = Field(..., description=\"Overall type of the dataset: structured, unstructured, time-series, etc.\")\n",
    "    columns: List[ColumnInfo] = Field(..., description=\"List of column names with their data types\")\n",
    "\n",
    "# --------- 2. Load and Preview the Dataset ---------\n",
    "# Load your dataset (replace this with the path to your file)\n",
    "df = pd.read_csv(\"sales.csv\")\n",
    "\n",
    "# Get the first few rows as preview\n",
    "data_preview = df.head(5).to_json(orient=\"records\", lines=False)\n",
    "\n",
    "# Get column schema\n",
    "column_schema = df.dtypes.apply(lambda x: str(x)).to_dict()\n",
    "\n",
    "# Convert to formatted string for prompt\n",
    "formatted_column_schema = \"\\n\".join([f\"- {col}: {dtype}\" for col, dtype in column_schema.items()])\n",
    "\n",
    "# --------- 3. Build Prompt Template ---------\n",
    "prompt_template = f\"\"\"\n",
    "You are given a sample of a dataset including its first 5 rows and column schema.\n",
    "\n",
    "Your task is to:\n",
    "1. Accurately determine the overall type of the dataset.\n",
    "   - Choose one or more of the following: \"structured\", \"unstructured\", \"time-series\", \"text\", \"image\", etc.\n",
    "2. List all column names along with their corresponding data types (such as int64, float64, object, datetime64, etc.).\n",
    "\n",
    "Do not perform any data cleaning, visualization suggestions, or further analysis.\n",
    "\n",
    "Respond only in structured JSON format that conforms exactly to the following schema:\n",
    "\n",
    "{{\n",
    "  \"data_type\": \"<overall_data_type>\",\n",
    "  \"columns\": [\n",
    "    {{ \"column_name\": \"<name1>\", \"data_type\": \"<type1>\" }},\n",
    "    ...\n",
    "  ]\n",
    "}}\n",
    "\n",
    "### Dataset Preview:\n",
    "{data_preview}\n",
    "\n",
    "### Column Schema:\n",
    "{formatted_column_schema}\n",
    "\"\"\"\n",
    "\n",
    "# --------- 4. Define Agent ---------\n",
    "agent = Agent(\n",
    "    role=\"Data Type Detection Agent\",\n",
    "    goal=\"Identify the overall type of a dataset and list its columns and their data types.\",\n",
    "    backstory=\"This agent specializes in understanding data formats for structured and unstructured datasets.\",\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# --------- 5. Define Task ---------\n",
    "task = Task(\n",
    "    description=prompt_template,\n",
    "    expected_output=\"JSON object with 'data_type' and 'columns' fields describing the dataset structure.\",\n",
    "    output_json=DataUnderstandingOutput,\n",
    "    output_file=os.path.join(output_dir, \"data_structure_analysis.json\"),\n",
    "    agent=agent,\n",
    ")\n",
    "\n",
    "# --------- 6. Run the Crew ---------\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
